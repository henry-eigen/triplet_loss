{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, Dropout, Convolution2D\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model,normalize\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from custom_lib.triplet_utils import buildDataSet, build_model\n",
    "from custom_lib.triplet_utils import get_batch_hard, compute_probs\n",
    "from custom_lib.triplet_utils import add_top, remove_top\n",
    "\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.attacks.projected_gradient_descent import ProjectedGradientDescent\n",
    "from art.attacks.iterative_method import BasicIterativeMethod\n",
    "from art.defences.adversarial_trainer import AdversarialTrainer\n",
    "from art.attacks.fast_gradient import FastGradientMethod\n",
    "\n",
    "from custom_lib.build_resnet import resnet_v1, resnet_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_lib.triplet_loss import batch_hard_triplet_loss\n",
    "from custom_lib.triplet_loss import batch_all_triplet_loss\n",
    "from custom_lib.triplet_loss import mixed_loss\n",
    "from tensorflow.contrib.losses import metric_learning\n",
    "\n",
    "def keras_batch_hard_triplet_loss(labels, y_pred):\n",
    "    labels = K.flatten(labels)\n",
    "    return batch_hard_triplet_loss(labels, y_pred, margin = 0.7)\n",
    "\n",
    "def keras_batch_all_triplet_loss(labels, y_pred):\n",
    "    labels = K.flatten(labels)\n",
    "    return batch_all_triplet_loss(labels, y_pred, margin = 0.7)\n",
    "\n",
    "def keras_semi_hard_loss(labels, y_pred):\n",
    "    labels = K.flatten(labels)\n",
    "    return metric_learning.triplet_semihard_loss(labels, y_pred, margin=0.7)\n",
    "\n",
    "def keras_mixed_loss(labels, y_pred):\n",
    "    labels = K.flatten(labels)\n",
    "    return mixed_loss(labels, y_pred, margin = 0.7, ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_cpu():\n",
    "    p = psutil.Process()\n",
    "\n",
    "    for i in p.threads():\n",
    "        temp = psutil.Process(i.id)\n",
    "\n",
    "        temp.cpu_affinity([i for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "val_train = to_categorical(y_train, 10)\n",
    "val_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "img_rows, img_cols = 32, 32\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "in_shape = input_shape\n",
    "\n",
    "dataset_train, dataset_test, x_train_origin, y_train_origin, x_test_origin, y_test_origin = buildDataSet(cifar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = resnet_v1(input_shape=in_shape)\n",
    "model.load_weights(\"resnet.h5\")\n",
    "\n",
    "sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "'''\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/heigen/.conda/envs/cenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/heigen/.conda/envs/cenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From ../custom_lib/triplet_loss.py:43: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-6\n",
    "batch_size=64\n",
    "epochs=10\n",
    "\n",
    "model_end = resnet_emb(input_shape)\n",
    "model_end.load_weights(\"resnet_adv.h5\")\n",
    "\n",
    "model_end.compile(loss=keras_mixed_loss,\n",
    "              optimizer=Adam(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_in = Input(shape=in_shape)\n",
    "base_out = model_end(base_in)\n",
    "x = Dense(10, activation='softmax')(base_out)\n",
    "\n",
    "full_model = Model(inputs=base_in, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/heigen/.conda/envs/cenv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 22s 434us/step - loss: 2.1843 - acc: 0.6515 - val_loss: 1.9612 - val_acc: 0.8588\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 1.7414 - acc: 0.9051 - val_loss: 1.5797 - val_acc: 0.8617\n",
      "WARNING:tensorflow:From /home/heigen/.conda/envs/cenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3298: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_full()\n",
    "\n",
    "adv_train, adv_test = generate_advs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/heigen/.conda/envs/cenv/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 100000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 94s 936us/step - loss: 1.3527 - val_loss: 1.0805\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 82s 815us/step - loss: 0.9650 - val_loss: 0.8477\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 81s 808us/step - loss: 0.8689 - val_loss: 0.8278\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 112s 1ms/step - loss: 0.8510 - val_loss: 0.8179\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 73s 730us/step - loss: 0.8381 - val_loss: 0.8100\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 82s 820us/step - loss: 0.8263 - val_loss: 0.8016\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 82s 821us/step - loss: 0.8142 - val_loss: 0.7923\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 81s 814us/step - loss: 0.8020 - val_loss: 0.7828\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 80s 795us/step - loss: 0.7905 - val_loss: 0.7738\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 78s 782us/step - loss: 0.7798 - val_loss: 0.7655\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 79s 787us/step - loss: 0.7702 - val_loss: 0.7584\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 77s 771us/step - loss: 0.7619 - val_loss: 0.7523\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 106s 1ms/step - loss: 0.7548 - val_loss: 0.7473\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 79s 794us/step - loss: 0.7490 - val_loss: 0.7430\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 82s 822us/step - loss: 0.7443 - val_loss: 0.7400\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 82s 817us/step - loss: 0.7407 - val_loss: 0.7372\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 78s 777us/step - loss: 0.7371 - val_loss: 0.7359\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 77s 773us/step - loss: 0.7233 - val_loss: 0.7210\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 77s 769us/step - loss: 0.6942 - val_loss: 0.7222\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 78s 775us/step - loss: 0.6740 - val_loss: 0.7281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f33b8742f98>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = np.concatenate((x_train, adv_train), axis=0)\n",
    "test_set = np.concatenate((y_train, y_train), axis=0)\n",
    "\n",
    "batch_size=64\n",
    "epochs=20\n",
    "learning_rate = 2e-5\n",
    "\n",
    "model_end.compile(loss=keras_batch_hard_triplet_loss,\n",
    "              optimizer=Adam(learning_rate))\n",
    "\n",
    "model_end.fit(train_set, test_set,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              shuffle=True,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_end.save_weights(\"resnet_ad_t.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 2.0830 - acc: 0.3417 - val_loss: 2.0305 - val_acc: 0.3783\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 1.9708 - acc: 0.3898 - val_loss: 1.9442 - val_acc: 0.3813\n",
      "10000/10000 [==============================] - 2s 167us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.126754496383667, 0.2666]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full(2)\n",
    "\n",
    "adv_train, adv_test = generate_advs()\n",
    "\n",
    "full_model.evaluate(adv_test, val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8976"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preds = full_model.predict(x_test)\n",
    "\n",
    "(np.argmax(preds, axis=1) == 4).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "100000/100000 [==============================] - 253s 3ms/step - loss: 1.5367 - val_loss: 1.0269\n",
      "Epoch 2/15\n",
      "100000/100000 [==============================] - 115s 1ms/step - loss: 1.4099 - val_loss: 1.0999\n",
      "Epoch 3/15\n",
      "100000/100000 [==============================] - 67s 668us/step - loss: 1.2797 - val_loss: 1.1054\n",
      "Epoch 4/15\n",
      "100000/100000 [==============================] - 67s 672us/step - loss: 1.1495 - val_loss: 1.0202\n",
      "Epoch 5/15\n",
      "100000/100000 [==============================] - 66s 659us/step - loss: 0.9661 - val_loss: 0.8802\n",
      "Epoch 6/15\n",
      "100000/100000 [==============================] - 67s 668us/step - loss: 0.9000 - val_loss: 0.8504\n",
      "Epoch 7/15\n",
      "100000/100000 [==============================] - 75s 752us/step - loss: 0.8813 - val_loss: 0.8382\n",
      "Epoch 8/15\n",
      "100000/100000 [==============================] - 94s 942us/step - loss: 0.8699 - val_loss: 0.8310\n",
      "Epoch 9/15\n",
      "100000/100000 [==============================] - 108s 1ms/step - loss: 0.8616 - val_loss: 0.8262\n",
      "Epoch 10/15\n",
      "100000/100000 [==============================] - 68s 680us/step - loss: 0.8549 - val_loss: 0.8224\n",
      "Epoch 11/15\n",
      "100000/100000 [==============================] - 217s 2ms/step - loss: 0.8490 - val_loss: 0.8194\n",
      "Epoch 12/15\n",
      "100000/100000 [==============================] - 116s 1ms/step - loss: 0.8435 - val_loss: 0.8163\n",
      "Epoch 13/15\n",
      "100000/100000 [==============================] - 69s 690us/step - loss: 0.8380 - val_loss: 0.8129\n",
      "Epoch 14/15\n",
      "100000/100000 [==============================] - 96s 959us/step - loss: 0.8318 - val_loss: 0.8089\n",
      "Epoch 15/15\n",
      "100000/100000 [==============================] - 223s 2ms/step - loss: 0.8260 - val_loss: 0.8053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7fe85c6a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = np.concatenate((x_train, adv_train), axis=0)\n",
    "test_set = np.concatenate((y_train, y_train), axis=0)\n",
    "\n",
    "batch_size=64\n",
    "epochs=15\n",
    "learning_rate = 5e-6\n",
    "\n",
    "model_end.compile(loss=keras_batch_hard_triplet_loss,\n",
    "              optimizer=Adam(learning_rate))\n",
    "\n",
    "model_end.fit(train_set, test_set,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              shuffle=True,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 17s 332us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0507572882080076, 0.42604]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from art.attacks.fast_gradient import FastGradientMethod\n",
    "\n",
    "art_model = KerasClassifier(clip_values=(0, 1.), model=full_model, use_logits=False)\n",
    "attack = FastGradientMethod(art_model, eps=0.04, batch_size=64)\n",
    "\n",
    "adv_imgs = attack.generate(x_test[0:10])\n",
    "\n",
    "restrict_cpu()\n",
    "    \n",
    "adv_train = attack.generate(x_train)\n",
    "adv_test = attack.generate(x_test)\n",
    "\n",
    "full_model.evaluate(adv_imgs, to_categorical(y_train, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.5396 - val_loss: 0.5849\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.5148 - val_loss: 0.5714\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.4962 - val_loss: 0.5621\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.4832 - val_loss: 0.5536\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 49s 985us/step - loss: 0.4741 - val_loss: 0.5477\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 49s 975us/step - loss: 0.4643 - val_loss: 0.5416\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 49s 985us/step - loss: 0.4568 - val_loss: 0.5377\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 49s 987us/step - loss: 0.4520 - val_loss: 0.5352\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.4464 - val_loss: 0.5312\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.4438 - val_loss: 0.5275\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 48s 962us/step - loss: 0.4355 - val_loss: 0.5258\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 46s 924us/step - loss: 0.4326 - val_loss: 0.5251\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 49s 971us/step - loss: 0.4284 - val_loss: 0.5227\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 47s 940us/step - loss: 0.4211 - val_loss: 0.5201\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 49s 983us/step - loss: 0.4223 - val_loss: 0.5202\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.4177 - val_loss: 0.5186\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 50s 991us/step - loss: 0.4149 - val_loss: 0.5165\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 49s 977us/step - loss: 0.4107 - val_loss: 0.5169\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 49s 983us/step - loss: 0.4135 - val_loss: 0.5147\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 49s 984us/step - loss: 0.4092 - val_loss: 0.5129\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 49s 978us/step - loss: 0.4071 - val_loss: 0.5124\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 49s 977us/step - loss: 0.4052 - val_loss: 0.5124\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.4018 - val_loss: 0.5119\n",
      "Epoch 24/50\n",
      "23744/50000 [=============>................] - ETA: 24s - loss: 0.4019"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-79ea19adf29f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m           validation_data=(adv_test, y_test))\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "epochs=50\n",
    "\n",
    "model_end.compile(loss=keras_semi_hard_loss,\n",
    "                  optimizer=Adam(5e-6))\n",
    "\n",
    "model_end.fit(adv_imgs, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(adv_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_end.save_weights(\"resnet_adv.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "[[0.226 1.38  1.378 1.388 1.381 1.405 1.408 1.35  1.388 1.389]\n",
      " [1.379 0.163 1.393 1.397 1.407 1.382 1.394 1.395 1.366 1.377]\n",
      " [1.382 1.394 0.186 1.384 1.395 1.363 1.395 1.392 1.403 1.397]\n",
      " [1.388 1.396 1.387 0.296 1.374 1.359 1.384 1.375 1.363 1.387]\n",
      " [1.382 1.407 1.396 1.371 0.208 1.392 1.398 1.376 1.405 1.387]\n",
      " [1.406 1.382 1.359 1.356 1.392 0.239 1.398 1.376 1.404 1.4  ]\n",
      " [1.408 1.395 1.397 1.384 1.398 1.396 0.177 1.403 1.404 1.387]\n",
      " [1.351 1.394 1.39  1.377 1.377 1.375 1.403 0.173 1.407 1.4  ]\n",
      " [1.388 1.367 1.402 1.361 1.405 1.404 1.403 1.407 0.173 1.394]\n",
      " [1.389 1.379 1.399 1.388 1.387 1.399 1.388 1.401 1.395 0.185]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "dist_matrix = np.zeros(shape=(10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    for j in range(10):\n",
    "        outs_1 = model_end.predict(dataset_train[i])\n",
    "        outs_2 = model_end.predict(dataset_train[j])\n",
    "        \n",
    "        norms = []\n",
    "        for k in range(1000):\n",
    "            norms.append(norm(outs_1[\n",
    "                np.random.randint(0, 5000)] - outs_2[\n",
    "                np.random.randint(0, 5000)]))\n",
    "        dist_matrix[i][j] = np.mean(norms)\n",
    "        '''\n",
    "\n",
    "plt.imshow(dist_matrix / dist_matrix.max(), cmap=\"Greys\")\n",
    "print(dist_matrix.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.528 1.27  1.221 1.243 1.305 1.313 1.324 1.29  1.217 1.263]\n",
      " [1.266 0.332 1.316 1.298 1.372 1.287 1.296 1.326 1.253 1.183]\n",
      " [1.217 1.311 0.51  1.206 1.228 1.223 1.264 1.292 1.324 1.335]\n",
      " [1.25  1.304 1.214 0.646 1.183 1.056 1.204 1.241 1.279 1.297]\n",
      " [1.297 1.37  1.232 1.181 0.532 1.217 1.245 1.211 1.352 1.346]\n",
      " [1.309 1.288 1.216 1.053 1.214 0.575 1.256 1.193 1.336 1.322]\n",
      " [1.328 1.295 1.266 1.198 1.248 1.263 0.371 1.334 1.33  1.299]\n",
      " [1.285 1.321 1.293 1.235 1.211 1.188 1.333 0.427 1.355 1.343]\n",
      " [1.22  1.259 1.322 1.279 1.349 1.337 1.328 1.358 0.42  1.286]\n",
      " [1.262 1.181 1.333 1.296 1.346 1.32  1.299 1.345 1.287 0.394]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_matrix = np.zeros(shape=(10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    for j in range(10):\n",
    "        outs_1 = model_end.predict(dataset_train[i])\n",
    "        outs_2 = model_end.predict(dataset_train[j])\n",
    "        \n",
    "        norms = []\n",
    "        for k in range(1000):\n",
    "            norms.append(norm(outs_1[\n",
    "                np.random.randint(0, 5000)] - outs_2[\n",
    "                np.random.randint(0, 5000)]))\n",
    "        dist_matrix[i][j] = np.mean(norms)\n",
    "\n",
    "plt.imshow(dist_matrix / dist_matrix.max(), cmap=\"Greys\")\n",
    "print(dist_matrix.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.fast_gradient import FastGradientMethod\n",
    "\n",
    "art_model = KerasClassifier(clip_values=(0, 1.), model=model, use_logits=False)\n",
    "attack = FastGradientMethod(art_model, eps=0.04, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_imgs = attack.generate(x_test[:2000])\n",
    "model.evaluate(adv_imgs, y_test[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.015 1.247 1.083 1.08  1.21  1.242 1.009 1.324 1.135 1.276]\n",
      " [1.259 0.932 1.179 1.177 1.277 1.236 0.937 1.307 1.213 1.035]\n",
      " [1.22  1.285 1.017 1.041 1.163 1.2   0.848 1.313 1.274 1.295]\n",
      " [1.271 1.289 1.088 1.019 1.138 1.155 0.76  1.303 1.284 1.301]\n",
      " [1.257 1.312 1.083 1.02  1.057 1.188 0.831 1.282 1.31  1.327]\n",
      " [1.27  1.287 1.049 0.985 1.143 1.174 0.794 1.298 1.286 1.304]\n",
      " [1.283 1.296 1.066 1.041 1.134 1.232 0.797 1.324 1.29  1.301]\n",
      " [1.246 1.273 1.093 1.043 1.066 1.133 0.862 1.2   1.301 1.299]\n",
      " [1.069 1.203 1.143 1.09  1.224 1.256 0.912 1.331 1.093 1.265]\n",
      " [1.231 0.985 1.152 1.145 1.251 1.237 0.88  1.316 1.202 1.11 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAMHUlEQVR4nO3dX2iddx3H8c+nabK2SdAGA5vtWANzShFkEmQ68GITplPcjWUVVtCb3kydIrjpYN1gG7uQoRcilKmMOSwsDiayqYPaDRl0y7qBtlEoUfufZqxtStstzfL1IhFru+Q8TX+/PcmX9wsGzTln33wJefc5eXrOE0eEAOSxou0FAJRF1EAyRA0kQ9RAMkQNJLOyxtD+/v4YHBwsPvfo0aPFZ0rSwMBAlbk1nD59usrc6enpKnOvueaaKnPHx8eLz6zxPStJJ0+eLD5zenpaMzMzfr/7qkQ9ODioRx55pPjcRx99tPhMSbrzzjuLz7Tf9+t9xXbt2lVl7sTERJW5999/f5W5mzdvLj5z06ZNxWdK0nPPPVd85vHjx+e9j6ffQDJEDSRD1EAyRA0kQ9RAMkQNJNMoattftP0P2/tt31d7KQCL1zFq212SfibpS5I2Svq67Y21FwOwOE2O1J+RtD8ixiNiStIOSXfUXQvAYjWJep2kgxd8fGjutv9je6vtUdujtV7KCKCzYifKImJ7RAxHxHB/f3+psQAuU5OoD0u69oKP18/dBmAJahL1a5I+ZnvIdo+kzZJ+V3ctAIvV8V1aETFt+1uS/iipS9IvI2Jv9c0ALEqjt15GxPOSnq+8C4ACeEUZkAxRA8kQNZAMUQPJEDWQTJULDx45ckTbtm0rPnfHjh3FZ0rSY489VnxmrQsPjo2NVZl79dVXV5k7NDRUZe7q1auLz6z1tX3wwQeLz3z44YfnvY8jNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQTJWriXZ3d1e5OuXtt99efKYkPf7448VnTk5OFp8pSVdddVWVuW+99VaVudddd12Vue+9917xmfv37y8+U5Luvffe4jNPnTo1730cqYFkiBpIhqiBZIgaSIaogWSIGkiGqIFkOkZt+1rbf7a9z/Ze2/d8EIsBWJwmLz6ZlvT9iNhju1/S67ZfjIh9lXcDsAgdj9QRcTQi9sz9+bSkMUnrai8GYHEu62WitjdIulHS7ve5b6ukrVK9lzIC6KzxiTLbfZJ+K+m7EXHJC5sjYntEDEfEcHd3d8kdAVyGRlHb7tZs0E9HxLN1VwJwJZqc/bakX0gai4jyb2cCUFSTI/XNkrZIusX2m3P/1XkPJIAr1vFEWUT8RZI/gF0AFMAryoBkiBpIhqiBZIgaSKbKhQenpqZ04MCB4nNrXGxOqnPBueuvv774TEnq6+urMrerq6vK3MHBwSpza7zA6fz588VnSvW+b+fDkRpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSKbK1URtq6enp/jc48ePF58pSStWlP+7LSKKz5SkG264ocrcl156qcrcU6dOVZnb29tbfObk5CW/obmIc+fOFZ+50PcXR2ogGaIGkiFqIBmiBpIhaiAZogaSIWogmcZR2+6y/Ybt39dcCMCVuZwj9T2SxmotAqCMRlHbXi/py5KeqLsOgCvV9Ej9E0k/kDQz3wNsb7U9anv0g/4l2wD+p2PUtr8i6XhEvL7Q4yJie0QMR8RwV1dXsQUBXJ4mR+qbJX3V9r8k7ZB0i+1fV90KwKJ1jDoifhgR6yNig6TNknZGxF3VNwOwKPw7NZDMZb2fOiJ2SdpVZRMARXCkBpIhaiAZogaSIWogGaIGkqlyNdGI0NTUVPG5/f39xWdK0tq1a4vPHBgYKD5Tkl5++eUqc1etWrWs5r7zzjvFZ/b19RWfKdW5Wu3Zs2fn/3zFPxuAVhE1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8lUuZrozMyM3n333eJzz58/X3ymJJ07d674zIMHDxafKUnd3d1V5o6Pj1eZGxFV5k5OThafWesKsDV+X7vtee/jSA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0k0yhq2x+2PWL777bHbH+29mIAFqfpi09+KukPEfE12z2S1lTcCcAV6Bi17Q9J+rykb0hSRExJKv/LpwEU0eTp95CkCUm/sv2G7Sds9178INtbbY/aHp2ZmSm+KIBmmkS9UtKnJf08Im6UdEbSfRc/KCK2R8RwRAyvWMH5N6AtTeo7JOlQROye+3hEs5EDWII6Rh0RxyQdtP3xuZtulbSv6lYAFq3p2e9vS3p67sz3uKRv1lsJwJVoFHVEvClpuPIuAArgjBaQDFEDyRA1kAxRA8kQNZBMlauJdnd3a3BwsPjckydPFp8pSadPny4+s6+vr/hMSdqwYUOVubWcOHGiytzbbrut+MxXXnml+Exp4St/1sCRGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkqlx4cGBgQFu2bCk+d+fOncVnStKxY8eKz6z163xffPHFKnMnJiaqzL377rurzH3hhReKz3zggQeKz5Skp556qvjMs2fPznsfR2ogGaIGkiFqIBmiBpIhaiAZogaSIWogmUZR2/6e7b22/2b7N7ZX1V4MwOJ0jNr2OknfkTQcEZ+U1CVpc+3FACxO06ffKyWttr1S0hpJR+qtBOBKdIw6Ig5L+rGkA5KOSjoVEX+6+HG2t9oetT165syZ8psCaKTJ0++1ku6QNCTpo5J6bd918eMiYntEDEfEcG9vb/lNATTS5On3FyT9MyImIuK8pGclfa7uWgAWq0nUByTdZHuNbUu6VdJY3bUALFaTn6l3SxqRtEfSX+f+n+2V9wKwSI3eTx0R2yRtq7wLgAJ4RRmQDFEDyRA1kAxRA8kQNZBMlauJnjhxQiMjI8XnPvTQQ8VnStIzzzxTfObhw4eLz5Skt99+u8rc/v7+KnPXrFlTZW5PT0/xma+++mrxmZK0adOm4jOffPLJee/jSA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJOOIKD/UnpD07wYP/Yikt4ovUM9y2nc57Sotr32Xwq7XRcTg+91RJeqmbI9GxHBrC1ym5bTvctpVWl77LvVdefoNJEPUQDJtR73cfnn9ctp3Oe0qLa99l/Surf5MDaC8to/UAAojaiCZ1qK2/UXb/7C93/Z9be3Rie1rbf/Z9j7be23f0/ZOTdjusv2G7d+3vctCbH/Y9ojtv9ses/3ZtndaiO3vzX0f/M32b2yvanuni7USte0uST+T9CVJGyV93fbGNnZpYFrS9yNio6SbJN29hHe90D2SxtpeooGfSvpDRHxC0qe0hHe2vU7SdyQNR8QnJXVJ2tzuVpdq60j9GUn7I2I8IqYk7ZB0R0u7LCgijkbEnrk/n9bsN926drdamO31kr4s6Ym2d1mI7Q9J+rykX0hSRExFxMl2t+popaTVtldKWiPpSMv7XKKtqNdJOnjBx4e0xEORJNsbJN0oaXe7m3T0E0k/kDTT9iIdDEmakPSruR8VnrDd2/ZS84mIw5J+LOmApKOSTkXEn9rd6lKcKGvIdp+k30r6bkRMtr3PfGx/RdLxiHi97V0aWCnp05J+HhE3SjojaSmfX1mr2WeUQ5I+KqnX9l3tbnWptqI+LOnaCz5eP3fbkmS7W7NBPx0Rz7a9Twc3S/qq7X9p9seaW2z/ut2V5nVI0qGI+O8znxHNRr5UfUHSPyNiIiLOS3pW0uda3ukSbUX9mqSP2R6y3aPZkw2/a2mXBdm2Zn/mG4uIx9vep5OI+GFErI+IDZr9uu6MiCV3NJGkiDgm6aDtj8/ddKukfS2u1MkBSTfZXjP3fXGrluCJvZVtfNKImLb9LUl/1OwZxF9GxN42dmngZklbJP3V9ptzt/0oIp5vcadMvi3p6bm/3MclfbPlfeYVEbttj0jao9l/FXlDS/Alo7xMFEiGE2VAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMv8BV9nBXlNA8eYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_matrix = np.zeros(shape=(10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    for j in range(10):\n",
    "        adv_imgs = attack.generate(dataset_train[i][:2500])\n",
    "        outs_1 = model_end.predict(adv_imgs)\n",
    "        outs_2 = model_end.predict(dataset_train[j])\n",
    "        \n",
    "        norms = []\n",
    "        for k in range(1000):\n",
    "            norms.append(norm(outs_1[\n",
    "                np.random.randint(0, 2500)] - outs_2[\n",
    "                np.random.randint(0, 5000)]))\n",
    "        dist_matrix[i][j] = np.mean(norms)\n",
    "\n",
    "plt.imshow(dist_matrix / dist_matrix.max(), cmap=\"Greys\")\n",
    "print(dist_matrix.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
