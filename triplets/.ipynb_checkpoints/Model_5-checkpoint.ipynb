{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import psutil\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, Dropout, Convolution2D, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform,he_uniform\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from custom_lib.triplet_utils import buildDataSet, build_model\n",
    "from custom_lib.triplet_utils import get_batch_hard, compute_probs\n",
    "from custom_lib.triplet_utils import add_top, remove_top\n",
    "\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.attacks.projected_gradient_descent import ProjectedGradientDescent\n",
    "from art.attacks.iterative_method import BasicIterativeMethod\n",
    "from art.defences.adversarial_trainer import AdversarialTrainer\n",
    "from art.attacks.fast_gradient import FastGradientMethod\n",
    "\n",
    "from custom_lib.build_resnet import resnet_v1, resnet_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_cpu():\n",
    "    p = psutil.Process()\n",
    "\n",
    "    for i in p.threads():\n",
    "        temp = psutil.Process(i.id)\n",
    "\n",
    "        temp.cpu_affinity([i for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-6\n",
    "batch_size=64\n",
    "epochs=10\n",
    "\n",
    "nb_classes = 10\n",
    "img_rows, img_cols = 32, 32\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "in_shape = input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/heigen/.conda/envs/cenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/heigen/.conda/envs/cenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 241.50 191.00\" width=\"242pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-187 237.5,-187 237.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139849397941360 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139849397941360</title>\n",
       "<polygon fill=\"none\" points=\"59,-146.5 59,-182.5 184,-182.5 184,-146.5 59,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-160.8\">input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139849397941136 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139849397941136</title>\n",
       "<polygon fill=\"none\" points=\"67.5,-73.5 67.5,-109.5 175.5,-109.5 175.5,-73.5 67.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-87.8\">model_1: Model</text>\n",
       "</g>\n",
       "<!-- 139849397941360&#45;&gt;139849397941136 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139849397941360-&gt;139849397941136</title>\n",
       "<path d=\"M121.5,-146.313C121.5,-138.289 121.5,-128.547 121.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"125,-119.529 121.5,-109.529 118,-119.529 125,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139849397516552 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139849397516552</title>\n",
       "<polygon fill=\"none\" points=\"0,-0.5 0,-36.5 117,-36.5 117,-0.5 0,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"58.5\" y=\"-14.8\">emb_out: Lambda</text>\n",
       "</g>\n",
       "<!-- 139849397941136&#45;&gt;139849397516552 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139849397941136-&gt;139849397516552</title>\n",
       "<path d=\"M106.249,-73.3129C98.511,-64.5918 88.9709,-53.8402 80.4576,-44.2459\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"82.8652,-41.6858 73.6101,-36.5288 77.6293,-46.3318 82.8652,-41.6858\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139854649317472 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139854649317472</title>\n",
       "<polygon fill=\"none\" points=\"135.5,-0.5 135.5,-36.5 233.5,-36.5 233.5,-0.5 135.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-14.8\">cat_out: Dense</text>\n",
       "</g>\n",
       "<!-- 139849397941136&#45;&gt;139854649317472 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139849397941136-&gt;139854649317472</title>\n",
       "<path d=\"M136.751,-73.3129C144.489,-64.5918 154.029,-53.8402 162.542,-44.2459\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"165.371,-46.3318 169.39,-36.5288 160.135,-41.6858 165.371,-46.3318\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- Base Model --------------------------\n",
    "\n",
    "base_model = resnet_emb(input_shape)\n",
    "base_model.load_weights(\"saved_models/old_base.h5\")\n",
    "\n",
    "base_in = Input(shape=in_shape)\n",
    "base_out = base_model(base_in)\n",
    "\n",
    "# -------------------- Emb Model ---------------------------\n",
    "\n",
    "emb_branch = Lambda(lambda t: K.l2_normalize(t,axis=-1), name=\"emb_out\")(base_out)\n",
    "#emb_branch = Lambda(lambda t: t, name=\"emb_out\")(base_out)\n",
    "                                                  \n",
    "# -------------------- Categorical Model -------------------\n",
    "\n",
    "cat_branch = Dense(10, activation='softmax', name=\"cat_out\")(base_out)\n",
    "\n",
    "# -------------------- Compile -----------------------------\n",
    "\n",
    "model = Model(inputs=base_in, \n",
    "              outputs=[emb_branch, cat_branch], \n",
    "              name=\"fullnet\")\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"emb_out\": euclidean_distance_loss,\n",
    "    \"cat_out\": \"categorical_crossentropy\",\n",
    "}\n",
    "\n",
    "lossWeights = {\"emb_out\": 5.0, \"cat_out\": 0.5}\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=5e-4), loss=losses, loss_weights=lossWeights, metrics=[\"accuracy\"])\n",
    "#model.compile(optimizer=Adam(lr=5e-4), loss=losses, loss_weights=lossWeights, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_in = Input(shape=in_shape)\n",
    "b_out = model(b_in)[1]\n",
    "\n",
    "adv_model = Model(inputs=b_in, outputs=b_out)\n",
    "adv_model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(1e-3), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/heigen/.conda/envs/cenv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.4106 - emb_out_loss: 1.0000 - cat_out_loss: 0.3238 - emb_out_acc: 2.0000e-05 - cat_out_acc: 0.8956 - val_loss: 0.4593 - val_emb_out_loss: 1.0000 - val_cat_out_loss: 0.3726 - val_emb_out_acc: 0.0000e+00 - val_cat_out_acc: 0.8807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2fb4111e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_train = np.zeros(shape=(x_train.shape[0], 128))\n",
    "dummy_test = np.zeros(shape=(x_test.shape[0], 128))\n",
    "\n",
    "model.fit(x_train, [dummy_train, y_train],\n",
    "          validation_data=(x_test, [dummy_test, y_test]),\n",
    "          epochs=1, \n",
    "          batch_size=32,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/heigen/.conda/envs/cenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3298: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "art_model = KerasClassifier(clip_values=(0, 1.), model=adv_model, use_logits=False)\n",
    "attack = ProjectedGradientDescent(art_model, norm=2, eps=8, random_eps=True, eps_step=2, max_iter=5, batch_size=16)\n",
    "\n",
    "adv_test = attack.generate(x_test[:10])\n",
    "\n",
    "restrict_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train = model.predict(x_train)[0]\n",
    "emb_test = model.predict(x_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(attack.classifier._model.layers[1].layers[1].layers[-8].get_weights()[0][0, 0, :4, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, Y, batch_size = 64):\n",
    "    \n",
    "    indices = np.arange(len(X))\n",
    "    \n",
    "    batch=[]\n",
    "    while True:\n",
    "            # it might be a good idea to shuffle your data before each epoch\n",
    "            np.random.shuffle(indices) \n",
    "            for i in indices:\n",
    "                batch.append(i)\n",
    "                if len(batch)==batch_size:\n",
    "                    adv_x = X[batch]\n",
    "                    VAL = model.predict(adv_x)[0]\n",
    "                    adv_x[:48] = attack.generate(adv_x[:48])\n",
    "                    yield adv_x, [VAL, Y[batch]]\n",
    "                    batch=[]\n",
    "\n",
    "train_generator = batch_generator(x_train, y_train, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, Y, batch_size = 64):\n",
    "    \n",
    "    indices = np.arange(len(X))\n",
    "    \n",
    "    batch=[]\n",
    "    while True:\n",
    "            # it might be a good idea to shuffle your data before each epoch\n",
    "            np.random.shuffle(indices) \n",
    "            for i in indices:\n",
    "                batch.append(i)\n",
    "                if len(batch)==batch_size:\n",
    "                    adv_x = X[batch]\n",
    "                    VAL = model.predict(adv_x)[0]\n",
    "                    adv_x = attack.generate(adv_x)\n",
    "                    \n",
    "                    x_full = np.concatenate((X[batch], adv_x), axis=0)\n",
    "                    e_full = np.concatenate((VAL, VAL), axis=0)\n",
    "                    y_full = np.concatenate((Y[batch], Y[batch]), axis=0)\n",
    "                    \n",
    "                    yield x_full, [e_full, y_full]\n",
    "                    batch=[]\n",
    "\n",
    "train_generator = batch_generator(x_train, y_train, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 6.7149947844445705\n",
      "emb_out_loss 0.5519348978996277\n",
      "cat_out_loss 7.662679757922888\n",
      "emb_out_acc 0.5078125\n",
      "cat_out_acc 0.4921875\n"
     ]
    }
   ],
   "source": [
    "batch = train_generator.__next__()\n",
    "\n",
    "loss = model.evaluate(batch[0], batch[1], verbose=0)\n",
    "\n",
    "for i, l in enumerate(model.metrics_names):\n",
    "    print(l, loss[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n",
      "\n",
      " ------------- \n",
      "\n",
      "[125] Time for 125 iterations: 1.1 mins, Train Loss: (0.4050372, 2.2827613, 0.213)\n",
      "\n",
      " ------------- \n",
      "\n",
      "[250] Time for 250 iterations: 2.1 mins, Train Loss: (0.04001812, 2.3456652, 0.0988125)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f8ae0936fb14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-bfcad3da9abd>\u001b[0m in \u001b[0;36mbatch_generator\u001b[0;34m(X, Y, batch_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0madv_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mVAL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     \u001b[0madv_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mx_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/art/attacks/projected_gradient_descent.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi_max_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 adv_x = self._compute(adv_x, x, targets, self.eps, self.eps_step, self._project,\n\u001b[0;32m--> 134\u001b[0;31m                                       self.num_random_init > 0 and i_max_iter == 0)\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_random_init\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/art/attacks/fast_gradient.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self, x, x_init, y, eps, eps_step, project, random_init)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;31m# Get perturbation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mperturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_perturbation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;31m# Apply perturbation and clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/art/attacks/fast_gradient.py\u001b[0m in \u001b[0;36m_compute_perturbation\u001b[0;34m(self, batch, batch_labels)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Get gradient wrt loss; invert it if attack is targeted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargeted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Apply norm bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/art/classifiers/keras.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preprocessed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_preprocessing_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "evaluate_every = 125 # interval for evaluating on one-shot tasks\n",
    "n_iter = 16_000 # No. of training iterations\n",
    "n_val = 250 # how many one-shot tasks to validate on\n",
    "n_iteration=0\n",
    "\n",
    "loss_list = []\n",
    "total_loss = []\n",
    "\n",
    "emb_vals = []\n",
    "cat_vals = []\n",
    "acc_vals = []\n",
    "\n",
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "for i in range(1, n_iter+1):\n",
    "    \n",
    "    batch = train_generator.__next__()\n",
    "    \n",
    "    loss = model.train_on_batch(batch[0], batch[1])\n",
    "    \n",
    "    emb_vals.append(loss[1])\n",
    "    cat_vals.append(loss[2])\n",
    "    acc_vals.append(loss[4])\n",
    "    \n",
    "    n_iteration += 1\n",
    "    \n",
    "    if i % 4000 == 0:\n",
    "        K.set_value(model.optimizer.lr, K.get_value(model.optimizer.lr)/2.0)\n",
    "    \n",
    "    if i % evaluate_every == 0:\n",
    "        ploss = (np.mean(emb_vals), np.mean(cat_vals), np.mean(acc_vals))\n",
    "        loss_list.append(ploss)\n",
    "        emb_vals = []\n",
    "        cat_vals = []\n",
    "        acc_vals = []\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\".format(i, (time.time()-t_start)/60.0,ploss,n_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base images:\n",
      "loss 0.7551560568809509\n",
      "acc 0.8267\n",
      "\n",
      "Adv images:\n",
      "loss 2.1921155786514284\n",
      "acc 0.294375\n"
     ]
    }
   ],
   "source": [
    "eval_loss = adv_model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Base images:\")\n",
    "for i, name in enumerate(adv_model.metrics_names):\n",
    "    print(name, eval_loss[i])\n",
    "\n",
    "losses = []\n",
    "accs = []\n",
    "\n",
    "\n",
    "for i in range(0, 8000, 32):\n",
    "    adv_test = attack.generate(x_test[i:i+32])\n",
    "    eval_loss = adv_model.evaluate(adv_test, y_test[i:i+32], verbose=0)\n",
    "    losses.append(eval_loss[0])\n",
    "    accs.append(eval_loss[1])\n",
    "\n",
    "print(\"\\nAdv images:\")\n",
    "print('loss', np.mean(losses))\n",
    "print('acc', np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
